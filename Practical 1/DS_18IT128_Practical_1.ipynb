{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS 18IT098 Practical 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxIQgVhoi_0y"
      },
      "source": [
        "#Importing the necessary libraries\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bNQsHdIjfty"
      },
      "source": [
        "#Defing the url to be scraped.\n",
        "url = \"https://www.flipkart.com/search?q=laptop&sid=6bo%2Cb5g&as=on&as-show=on&otracker=AS_QueryStore_OrganicAutoSuggest_1_6_na_na_na&otracker1=AS_QueryStore_OrganicAutoSuggest_1_6_na_na_na&as-pos=1&as-type=RECENT&suggestionId=laptop%7CLaptops&requestId=6c2143cc-b81d-4c06-b8b0-2fa342ae6cfd&as-searchtext=laptop\"\n",
        "\n",
        "#Getting the response from that url\n",
        "response = requests.get(url)\n",
        "\n",
        "#Creating a BeautifulSoup object using that response.\n",
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE3kEeg-kl_k"
      },
      "source": [
        "#Making empty lists for the data to be extracted.\n",
        "products = []\n",
        "ratings = []\n",
        "prices = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uypsPzkAnAyQ"
      },
      "source": [
        "#Fetching the data from the response using the bs4 object and iterating it over and appending it in the appropriate list.\n",
        "for name in soup.find_all('div', {'class':'_4rR01T'}):\n",
        "  products.append(name.string)\n",
        "\n",
        "for rating in soup.find_all('div', {'class': '_3LWZlK'}):\n",
        "  ratings.append(rating.contents[0])\n",
        "\n",
        "for price in soup.find_all('div', {'class': '_30jeq3 _1_WHN1'}):\n",
        "  prices.append(price.string)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go9zK5xnp2HB"
      },
      "source": [
        "#Code for making an excel sheet for the data that was extracted.\n",
        "df = pd.DataFrame()\n",
        "\n",
        "df['Product Name'] = products\n",
        "df['Ratings'] = ratings[0:len(products)]\n",
        "df['Price'] = prices[0:len(products)]\n",
        "\n",
        "df.to_excel('/content/results.xlsx', index = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}